{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from braindecode.models.deep4 import Deep4Net\n",
    "from braindecode.datasets.bcic_iv_2a import BCICompetition4Set2A\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import LossMonitor, MisclassMonitor, \\\n",
    "    RuntimeMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs, NoDecrease, Or\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "from braindecode.torch_ext.constraints import MaxNormDefaultConstraint\n",
    "from braindecode.torch_ext.util import set_random_seeds, np_to_var\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "from braindecode.datautil.signalproc import (bandpass_cnt,\n",
    "                                             exponential_running_standardize)\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(data_folder, subject_len):\n",
    "    train_filename = 'A{:02d}T.gdf'.format(subject_id)\n",
    "    test_filename = 'A{:02d}E.gdf'.format(subject_id)\n",
    "    train_filepath = os.path.join(data_folder, train_filename)\n",
    "    test_filepath = os.path.join(data_folder, test_filename)\n",
    "    train_label_filepath = train_filepath.replace('.gdf', '.mat')\n",
    "    test_label_filepath = test_filepath.replace('.gdf', '.mat')\n",
    "\n",
    "    train_loader = BCICompetition4Set2A(\n",
    "        train_filepath, labels_filename=train_label_filepath)\n",
    "    test_loader = BCICompetition4Set2A(\n",
    "        test_filepath, labels_filename=test_label_filepath)\n",
    "    train_cnt = train_loader.load()\n",
    "    test_cnt = test_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(cnt):\n",
    "    # Preprocessing\n",
    "\n",
    "    train_cnt = train_cnt.drop_channels(['STI 014', 'EOG-left',\n",
    "                                         'EOG-central', 'EOG-right'])\n",
    "    assert len(train_cnt.ch_names) == 22\n",
    "    # lets convert to millvolt for numerical stability of next operations\n",
    "    train_cnt = mne_apply(lambda a: a * 1e6, train_cnt)\n",
    "    train_cnt = mne_apply(\n",
    "        lambda a: bandpass_cnt(a, low_cut_hz, high_cut_hz, train_cnt.info['sfreq'],\n",
    "                               filt_order=3,\n",
    "                               axis=1), train_cnt)\n",
    "    train_cnt = mne_apply(\n",
    "        lambda a: exponential_running_standardize(a.T, factor_new=factor_new,\n",
    "                                                  init_block_size=init_block_size,\n",
    "                                                  eps=1e-4).T,\n",
    "        train_cnt)\n",
    "\n",
    "    test_cnt = test_cnt.drop_channels(['STI 014', 'EOG-left',\n",
    "                                       'EOG-central', 'EOG-right'])\n",
    "    assert len(test_cnt.ch_names) == 22\n",
    "    test_cnt = mne_apply(lambda a: a * 1e6, test_cnt)\n",
    "    test_cnt = mne_apply(\n",
    "        lambda a: bandpass_cnt(a, low_cut_hz, high_cut_hz, test_cnt.info['sfreq'],\n",
    "                               filt_order=3,\n",
    "                               axis=1), test_cnt)\n",
    "    test_cnt = mne_apply(\n",
    "        lambda a: exponential_running_standardize(a.T, factor_new=factor_new,\n",
    "                                                  init_block_size=init_block_size,\n",
    "                                                  eps=1e-4).T,\n",
    "        test_cnt)\n",
    "    return train_cnt, test_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(data_folder, subject_id, low_cut_hz, model, cuda):\n",
    "    ival = [-500, 4000]\n",
    "    max_epochs = 1600\n",
    "    max_increase_epochs = 160\n",
    "    batch_size = 60\n",
    "    high_cut_hz = 38\n",
    "    factor_new = 1e-3\n",
    "    init_block_size = 1000\n",
    "    valid_set_fraction = 0.2\n",
    "\n",
    "    marker_def = OrderedDict([('Left Hand', [1]), ('Right Hand', [2],),\n",
    "                              ('Foot', [3]), ('Tongue', [4])])\n",
    "\n",
    "    train_set = create_signal_target_from_raw_mne(train_cnt, marker_def, ival)\n",
    "    test_set = create_signal_target_from_raw_mne(test_cnt, marker_def, ival)\n",
    "\n",
    "    train_set, valid_set = split_into_two_sets(\n",
    "        train_set, first_set_fraction=1-valid_set_fraction)\n",
    "\n",
    "    set_random_seeds(seed=20190706, cuda=cuda)\n",
    "\n",
    "    n_classes = 4\n",
    "    n_chans = int(train_set.X.shape[1])\n",
    "    input_time_length = train_set.X.shape[2]\n",
    "    if model == 'shallow':\n",
    "        model = ShallowFBCSPNet(n_chans, n_classes, input_time_length=input_time_length,\n",
    "                            final_conv_length='auto').create_network()\n",
    "    elif model == 'deep':\n",
    "        model = Deep4Net(n_chans, n_classes, input_time_length=input_time_length,\n",
    "                            final_conv_length='auto').create_network()\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    log.info(\"Model: \\n{:s}\".format(str(model)))\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    iterator = BalancedBatchSizeIterator(batch_size=batch_size)\n",
    "\n",
    "    stop_criterion = Or([MaxEpochs(max_epochs),\n",
    "                         NoDecrease('valid_misclass', max_increase_epochs)])\n",
    "\n",
    "    monitors = [LossMonitor(), MisclassMonitor(), RuntimeMonitor()]\n",
    "\n",
    "    model_constraint = MaxNormDefaultConstraint()\n",
    "\n",
    "    exp = Experiment(model, train_set, valid_set, test_set, iterator=iterator,\n",
    "                     loss_function=F.nll_loss, optimizer=optimizer,\n",
    "                     model_constraint=model_constraint,\n",
    "                     monitors=monitors,\n",
    "                     stop_criterion=stop_criterion,\n",
    "                     remember_best_column='valid_misclass',\n",
    "                     run_after_early_stop=True, cuda=cuda)\n",
    "    exp.run()\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                        level=logging.DEBUG, stream=sys.stdout)\n",
    "    # Should contain both .gdf files and .mat-labelfiles from competition\n",
    "    data_folder = '/Users/debaojian/OneDrive/OneDrive - UNSW/UNSW/Research/EEG/BCI_Competition/'\n",
    "    subject_id = 1 # 1-9\n",
    "    low_cut_hz = 4 # 0 or 4\n",
    "    model = 'shallow' #'shallow' or 'deep'\n",
    "    cuda = True\n",
    "    exp = run_exp(data_folder, subject_id, low_cut_hz, model, cuda)\n",
    "    log.info(\"Last 10 epochs\")\n",
    "    log.info(\"\\n\" + str(exp.epochs_df.iloc[-10:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
